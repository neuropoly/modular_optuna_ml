{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf01c257-225d-4646-9315-3129cf3a99a0",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d199ddb1-292a-4a7c-b7a0-0b6174d3cfa0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5052fd7-31a0-44eb-873c-fde1985b7f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, permutations\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlite3 import connect\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(707260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d8e32-1da6-4701-b5f3-b051f782483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = connect('../results.db')\n",
    "tables = pd.read_sql(\n",
    "    \"SELECT * FROM sqlite_master\", \n",
    "    con=con\n",
    ").loc[:, 'name']\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f1690092a90cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(data_label):\n",
    "    # Obligatory clinical exception\n",
    "    if 'clinical' in data_label:\n",
    "        return 'clin_only'\n",
    "\n",
    "    # Otherwise the dataset type can be queried by a simple if chain\n",
    "    components = []\n",
    "    if 'img_only' in data_label:\n",
    "        components.append('img_only')\n",
    "    elif 'full' in data_label:\n",
    "        components.append('full')\n",
    "    # Then whether its in the C2C6 or C2C7 range\n",
    "    if 'c2c7' in data_label:\n",
    "        components.append('C2C7')\n",
    "    else:\n",
    "        components.append('C2C6')\n",
    "    return '_'.join(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aad00b956de637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_seg_algo(data_label):\n",
    "    # Obligatory clinical exception\n",
    "    if 'clinical' in data_label:\n",
    "        return 'none'\n",
    "\n",
    "    # Get the segmentation algorithm\n",
    "    if 'deepseg' in data_label:\n",
    "        return 'deepseg'\n",
    "    elif 'softseg' in data_label:\n",
    "        return 'softseg'\n",
    "    # Return the results joined by underscores\n",
    "    return 'unk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbbf9f25fd0cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_contrast(data_label):\n",
    "    # Obligatory clinical exception\n",
    "    if 'clinical' in data_label:\n",
    "        return 'none'\n",
    "\n",
    "    # Currently only T1 and T2 contrasts exist\n",
    "    if 'T1w' in data_label:\n",
    "        return 'T1'\n",
    "    elif 'T2w' in data_label:\n",
    "        return 'T2'\n",
    "    return 'unk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f959089bc96ea676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_orientation(data_label):\n",
    "    # Obligatory clinical exception\n",
    "    if 'clinical' in data_label:\n",
    "        return 'none'\n",
    "\n",
    "    # Currently only T1 and T2 contrasts exist\n",
    "    if 'sag' in data_label:\n",
    "        return 'sag'\n",
    "    elif 'axial' in data_label:\n",
    "        return 'axial'\n",
    "    return 'unk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee48af69306561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pre_processing(data_label):\n",
    "    # We have 5 variants this time\n",
    "    if 'rfe_pca' in data_label:\n",
    "        return 'rfe_pca'\n",
    "    elif 'pca_rfe' in data_label:\n",
    "        return 'pca_rfe'\n",
    "    elif 'rfe' in data_label:\n",
    "        return 'rfe'\n",
    "    elif 'pca' in data_label:\n",
    "        return 'pca'\n",
    "    elif 'noprep' in data_label:\n",
    "        return 'none'\n",
    "    return 'unk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814b1713-9069-4e57-9c12-aee466db015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = {}\n",
    "\n",
    "bad_vals = 0\n",
    "\n",
    "analysis_idx = ['seg_algo', 'dataset', 'model', 'weight', 'ori', 'prep']\n",
    "\n",
    "con = connect('../results.db')\n",
    "for t in tables:\n",
    "    # Pull the dataframe from the database\n",
    "    try:\n",
    "        df = pd.read_sql(\n",
    "            f\"SELECT * FROM {t}\", \n",
    "            con=con\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Failed to read table {t}, ignoring it\")\n",
    "        bad_vals += 1\n",
    "        continue\n",
    "\n",
    "    # If the table represents a study which wasn't run to completion, end early and report it\n",
    "    if df.shape[0] < 1000:\n",
    "        # print(f\"Study {t} was not completed\")\n",
    "        bad_vals += 1\n",
    "        continue\n",
    "\n",
    "    # Split the DataFrame's label into its components\n",
    "    label_comps = t.split('__')\n",
    "\n",
    "    # The model is always the second element of study tag\n",
    "    model = label_comps[1]\n",
    "\n",
    "    # Dataset is always the last element of the study tag\n",
    "    data_description = label_comps[-1]\n",
    "\n",
    "    # Interpret the data label bit by bit to build up the dataframe\n",
    "    df['seg_algo'] = parse_seg_algo(data_description)\n",
    "    df['dataset'] = parse_dataset(data_description)\n",
    "    df['model'] = model\n",
    "    df['weight'] = parse_contrast(data_description)\n",
    "    df['ori'] = parse_orientation(data_description)\n",
    "    df['prep'] = parse_pre_processing(data_description)\n",
    "\n",
    "    df_map[model + '_' + data_description] = df\n",
    "\n",
    "con.close()\n",
    "\n",
    "print(f\"\\nTotal No. bad values: {bad_vals}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e58198a-b430-42b3-91f0-09d5bf24afab",
   "metadata": {},
   "source": [
    "## Performance Metric Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e4735-83b7-4310-b2c1-bd2f873148f0",
   "metadata": {},
   "source": [
    "All metrics in the below index list are tracked for all analyses, so are safe to query (and stack) from all analytical permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c75c94-4887-42b6-9c5b-605f68790511",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_performance_metric_idxs = [\n",
    "    \"objective\",\n",
    "    \"balanced_accuracy (validate)\",\n",
    "    \"roc_auc (validate)\",\n",
    "    \"log_loss (validate)\",\n",
    "    \"balanced_accuracy (test)\",\n",
    "    \"roc_auc (test)\",\n",
    "    \"log_loss (test)\",\n",
    "    \"importance_by_permutation (test)\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091a76c4-d55c-46c7-b7d3-10a6bc7f61d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_idxs = [\n",
    "    \"replicate\",\n",
    "    \"trial\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4aec0-32b5-4c31-b5b7-c75875ac3c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_performance_metrics():\n",
    "    sub_dfs = []\n",
    "    for df in df_map.values():\n",
    "        sub_df = df.loc[:, [*analysis_idx, *study_idxs, *shared_performance_metric_idxs]]\n",
    "        sub_dfs.append(sub_df)\n",
    "    return pd.concat(sub_dfs)\n",
    "\n",
    "performance_metric_df = stack_performance_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720063883eb33f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec27bd8-67fb-43dd-8a32-b87bf113a6ed",
   "metadata": {},
   "source": [
    "# Patient Metric Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61272b01-a632-4658-88b8-7fb962edef71",
   "metadata": {},
   "source": [
    "## Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbb261-4dc6-47da-9d03-e48debb2f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_metric_df = pd.read_csv(\"../deepseg_data/clinical_only.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f17c7e-c649-45d0-9900-3f446b28bca7",
   "metadata": {},
   "source": [
    "## mJOA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0329de6-5f8c-41ee-93bd-ae8f725977d9",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f052f31f-72a7-4136-9aff-81894efc81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(data, cmap, legend_elements, xlabel, title, mean_offset=0, flip_mean_rot=False):\n",
    "    # Get the appropriate ranges for the data\n",
    "    min_range = int(np.min(data))-1\n",
    "    max_range = int(np.max(data))+1\n",
    "    \n",
    "    # Bin the data\n",
    "    hist, bins = np.histogram(\n",
    "        data, \n",
    "        np.array(range(min_range, max_range))+.1\n",
    "    )\n",
    "    \n",
    "    # Generate the figure\n",
    "    fig, ax = plt.subplots()\n",
    "        \n",
    "    # Iteratively color code the bars\n",
    "    for t, c in cmap.items():\n",
    "        mask = bins < t\n",
    "        to_display = np.array(range(min_range, t))+0.5\n",
    "        vals = hist[mask[:-1]]\n",
    "        ax.bar(\n",
    "            to_display, vals,\n",
    "            width=1, color=c,\n",
    "            align='edge',\n",
    "            edgecolor='black'\n",
    "        )\n",
    "        \n",
    "    # Add a mean line\n",
    "    data_mean = np.mean(data)\n",
    "    ax.axvline(data_mean, ls='--', c='black')\n",
    "    if flip_mean_rot:\n",
    "        ax.text(data_mean-0.5, ax.get_ylim()[1]-mean_offset, f\"Mean ({data_mean:.4})\", rotation=90)\n",
    "    else:\n",
    "        ax.text(data_mean+0.05, ax.get_ylim()[1]-mean_offset, f\"Mean ({data_mean:.4})\", rotation=-90)\n",
    "        \n",
    "    # Add in the legend\n",
    "    ax.legend(handles=legend_elements)\n",
    "    \n",
    "    # Add in labels\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Return the figure and axis\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418cf0c-0560-4a09-8a4f-ae8d7a8402e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limits so that all plots have consistent range\n",
    "xlim_min = int(np.min([*clinical_metric_df['mJOA initial'], *clinical_metric_df['mJOA 12 months']]))-1\n",
    "xlim_max = int(np.max([*clinical_metric_df['mJOA initial'], *clinical_metric_df['mJOA 12 months']]))+1\n",
    "\n",
    "ylim_min = 0\n",
    "ylim_max = int(np.max([\n",
    "    *np.histogram(clinical_metric_df['mJOA initial'], np.array(range(xlim_min, xlim_max))+.1)[0],\n",
    "    *np.histogram(clinical_metric_df['mJOA 12 months'], np.array(range(xlim_min, xlim_max))+.1)[0]\n",
    "]))+5\n",
    "\n",
    "# Color threshold map\n",
    "severity_cmap = {\n",
    "    18: 'blue',\n",
    "    17: 'green',\n",
    "    14: 'gold',\n",
    "    11: 'red'\n",
    "}\n",
    "\n",
    "# Generate a custom legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='red', edgecolor='black', label='Severe'),\n",
    "    Patch(facecolor='gold', edgecolor='black', label='Moderate'),\n",
    "    Patch(facecolor='green', edgecolor='black', label='Mild'),\n",
    "    Patch(facecolor='blue', edgecolor='black', label='Healthy'),\n",
    "]\n",
    "\n",
    "# DCM Severity labelling\n",
    "clinical_metric_df['DCM Severity initial'] = 'Severe'\n",
    "clinical_metric_df.loc[clinical_metric_df['mJOA initial'] > 11, 'DCM Severity initial'] = 'Moderate'\n",
    "clinical_metric_df.loc[clinical_metric_df['mJOA initial'] > 14, 'DCM Severity initial'] = 'Mild'\n",
    "clinical_metric_df.loc[clinical_metric_df['mJOA initial'] > 17, 'DCM Severity initial'] = 'Healthy'\n",
    "\n",
    "clinical_metric_df['DCM Severity 12 months'] = 'Severe'\n",
    "clinical_metric_df.loc[clinical_metric_df['mJOA 12 months'] > 11, 'DCM Severity 12 months'] = 'Moderate'\n",
    "clinical_metric_df.loc[clinical_metric_df['mJOA 12 months'] > 14, 'DCM Severity 12 months'] = 'Mild'\n",
    "clinical_metric_df.loc[clinical_metric_df['mJOA 12 months'] > 17, 'DCM Severity 12 months'] = 'Healthy'\n",
    "\n",
    "# Output path for the files\n",
    "mjoa_dist_out_path = Path('figures/mjoa_dist')\n",
    "if not mjoa_dist_out_path.exists():\n",
    "    mjoa_dist_out_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c24b1a-ffce-4a81-85e2-8f788547c1e1",
   "metadata": {},
   "source": [
    "### Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab91fb5-9a81-4edf-bc08-997dfc2ac38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "fig, ax = plot_distributions(\n",
    "    clinical_metric_df['mJOA initial'], severity_cmap, legend_elements,\n",
    "    'mJOA', 'Pre-Treatment mJOA Scores (Full)', 20\n",
    ")\n",
    "\n",
    "# Plot the total number of each severity class as text\n",
    "severity_counts = clinical_metric_df['DCM Severity initial'].value_counts()\n",
    "ax.text(9, 15, f\"({severity_counts['Severe']})\", c='black', size=12, horizontalalignment='center')\n",
    "ax.text(14, 44.5, f\"({severity_counts['Moderate']})\", c='black', size=12, horizontalalignment='center')\n",
    "ax.text(16.5, 33, f\"({severity_counts['Mild']})\", c='black', size=12, horizontalalignment='center')\n",
    "ax.text(18, 2.5, f\"({severity_counts['Healthy']})\", c='black', size=12, horizontalalignment='center')\n",
    "\n",
    "# Save and show the result\n",
    "fig.savefig(mjoa_dist_out_path / 'pre_treatment_mjoa.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d113761-8c0c-4e35-af5c-ee50440fbfc7",
   "metadata": {},
   "source": [
    "### 12 Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d26d7cc-1fef-4474-a8e9-e4b24fb7785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "fig, ax = plot_distributions(\n",
    "    clinical_metric_df['mJOA 12 months'], severity_cmap, legend_elements,\n",
    "    'mJOA', 'Post-Treatment mJOA Scores (Full)', 20, flip_mean_rot=True\n",
    ")\n",
    "\n",
    "# Plot the total number of each severity class as text\n",
    "severity_counts = clinical_metric_df['DCM Severity 12 months'].value_counts()\n",
    "ax.text(8.5, 3, f\"({severity_counts['Severe']})\", c='black', size=12, horizontalalignment='center')\n",
    "ax.text(13.5, 36, f\"({severity_counts['Moderate']})\", c='black', size=12, horizontalalignment='center')\n",
    "ax.text(16, 45, f\"({severity_counts['Mild']})\", c='black', size=12, horizontalalignment='center')\n",
    "ax.text(18, 37, f\"({severity_counts['Healthy']})\", c='black', size=12, horizontalalignment='center')\n",
    "\n",
    "# Save and show the result\n",
    "fig.savefig(mjoa_dist_out_path / 'post_treatment_mjoa.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad01ffb3-73de-4f92-9529-f488ff396cf8",
   "metadata": {},
   "source": [
    "### mJOA Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28350353-d34b-4dd5-a596-d1885dd2a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new color scheme and legend for this new style of data\n",
    "delta_cmap = {\n",
    "    8: 'springgreen',\n",
    "    0: 'white',\n",
    "    -1: 'salmon'\n",
    "}\n",
    "\n",
    "delta_legend_elements = [\n",
    "    Patch(facecolor='springgreen', edgecolor='black', label='Improved'),\n",
    "    Patch(facecolor='white', edgecolor='black', label='No Change'),\n",
    "    Patch(facecolor='salmon', edgecolor='black', label='Declined'),\n",
    "]\n",
    "\n",
    "xticks = (\n",
    "    list(range(-8, 9, 2)),\n",
    "    list(range(-8, 9, 2))\n",
    ")\n",
    "\n",
    "deltas = clinical_metric_df['mJOA 12 months'] - clinical_metric_df['mJOA initial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea28752-a836-48ab-83b1-3567c4c23e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the deltas\n",
    "fig, ax = plot_distributions(\n",
    "    deltas, delta_cmap, delta_legend_elements, \n",
    "    \"mJOA Change\", 'Change in mJOA Over 1 Year (Full)', 20, flip_mean_rot=True\n",
    ")\n",
    "\n",
    "# Plot the total number of each severity class as text\n",
    "change_counts = pd.cut(\n",
    "    deltas, \n",
    "    [-20, -1, 0, 20], \n",
    "    labels=['Declined', 'No Change', 'Improved']\n",
    ").value_counts()\n",
    "ax.text(-4.5, 9, f\"({change_counts['Declined']})\", c='black', size=12, verticalalignment='center')\n",
    "ax.text(-0.6, 40, f\"({change_counts['No Change']})\", c='black', size=12, verticalalignment='center')\n",
    "ax.text(4, 32, f\"({change_counts['Improved']})\", c='black', size=12, verticalalignment='center')\n",
    "\n",
    "# Save and show the result\n",
    "fig.savefig(mjoa_dist_out_path / 'treatment_mjoa_delta.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b446d5-eb86-43f6-a875-1b68faf8e95b",
   "metadata": {},
   "source": [
    "## Hirayabashi Recovery Ratio Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f5d7f7-e9b0-4b60-90bf-22c28b223f1e",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45fa902-ec49-44d3-80ab-5fd21a731fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Plot the KDE distribution onto an existing plot\n",
    "def plot_kde(ax, values, c='black', ls='-', label=None):\n",
    "    kde = gaussian_kde(values)\n",
    "    kde.covariance_factor = lambda: 0.15\n",
    "    kde._compute_covariance()\n",
    "    xs = np.linspace(np.min(values), np.max(values), 200)\n",
    "    ys = kde(xs)\n",
    "    ys /= np.linalg.norm(ys)\n",
    "    if label == None:\n",
    "        ax.plot(xs, ys, ls=ls, c=c)\n",
    "    else:\n",
    "        ax.plot(xs, ys, ls=ls, c=c, label=label)\n",
    "\n",
    "# Clean out invalid values from the set\n",
    "def clean_vals(df):\n",
    "    df2 = df[df != -np.inf]\n",
    "    df2 = df2.dropna()\n",
    "    return df2\n",
    "\n",
    "# Adds important reference lines to the plot\n",
    "def draw_line_references(ax):\n",
    "    # Significant improvement\n",
    "    ax.axvline(0.5, ls='-.', c='grey')\n",
    "    \n",
    "    # Baselines\n",
    "    ax.axhline(0, ls=\":\",  c='lightgrey') \n",
    "    ax.axvline(0, ls=\":\",  c='lightgrey')\n",
    "\n",
    "# The HRR Equation, for immediate reference within the plot\n",
    "hirabayashi_equation = r\"HRR = $\\frac{\\mathrm{mJOA (1 Year)} - \\mathrm{mJOA (Initial)}}{18 - \\mathrm{mJOA (Initial)}}$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb740816-3b59-45d3-9165-23b4d5044e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the HRR for our patients, skipping over initially healthy patients who could not improve whatsoever\n",
    "hrr_df = clinical_metric_df.loc[clinical_metric_df['DCM Severity initial'] != \"Healthy\", 'HRR']\n",
    "\n",
    "# Generate the initial plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot our reference lines\n",
    "draw_line_references(ax)\n",
    "\n",
    "# Plot the distributions by their initial severity class\n",
    "plot_kde(\n",
    "    ax, clean_vals(hrr_df[clinical_metric_df['DCM Severity initial'] == 'Severe']), ls='--', c='red', label='Severe'\n",
    ")\n",
    "plot_kde(\n",
    "    ax, clean_vals(hrr_df[clinical_metric_df['DCM Severity initial'] == 'Moderate']), ls='--', c='gold', label='Moderate'\n",
    ")\n",
    "plot_kde(\n",
    "    ax, clean_vals(hrr_df[clinical_metric_df['DCM Severity initial'] == 'Mild']), ls='--', c='green', label='Mild'\n",
    ")\n",
    "\n",
    "# Plot the overall distribution\n",
    "plot_kde(ax, hrr_df, c='blue', label='All')\n",
    "\n",
    "# Calculate the ratio above and below the HRR significance threshold, and add it\n",
    "good_ratio = np.sum(hrr_df >= 0.5)/hrr_df.shape[0]\n",
    "fair_ratio = np.sum(hrr_df < 0.5)/hrr_df.shape[0]\n",
    "\n",
    "ax.text(0.7, 0.238, f\"{good_ratio: .2f}\", c='purple')\n",
    "ax.text(-0.5, 0.238, f\"{fair_ratio: .2f}\", c='purple')\n",
    "\n",
    "# Add axis labels\n",
    "ax.set_xlabel('Hirabayashi Recovery Ratio (HRR)')\n",
    "ax.set_ylabel('Normalized Kernel Density Estimate')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend(title='Pre-Surgical DCM Severity')\n",
    "\n",
    "# Add hirabayashi equation directly to plot\n",
    "ax.text(-8, 0.15, hirabayashi_equation)\n",
    "\n",
    "# Add a title\n",
    "ax.set_title(\"Distribution of Hirabayashi Recovery Ratio\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(mjoa_dist_out_path / 'hirabayashi_ratios.svg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfd6a81-39c2-4261-80e7-27aeb53bfe14",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6b9b24-3298-41a2-95aa-b34716f64fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_continuous_demographics(col):\n",
    "    sns.displot(clinical_metric_df, x=col)\n",
    "    plt.title(f\"Patient Distribution ({col})\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figures/demo_dist/{'_'.join(col.lower().split(' '))}_dist.svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f7cf74-7a3d-42e7-915e-dcd2d1f7f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"figures/demo_dist/\")\n",
    "if not out_path.exists():\n",
    "    out_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029e164-7998-49bb-87e3-413b738bdcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_demographic_cols = [\n",
    "    \"Age\",\n",
    "    \"BMI\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a357f53-8841-47cc-98d2-316f754b4bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in continuous_demographic_cols:\n",
    "    plot_continuous_demographics(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62aa0f7-224b-4472-b0c1-817ac77cce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_demographics(col):\n",
    "    col_counts = clinical_metric_df[col].value_counts()\n",
    "    plt.pie(col_counts, labels=None, autopct=lambda x: f'{x: .2f}%')\n",
    "    plt.legend(labels=col_counts.index)\n",
    "    plt.title(f\"Patient Distribution ({col})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figures/demo_dist/{'_'.join(col.lower().split(' '))}_dist.svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb84c52-6ea9-4994-ab07-3cef87cfe408",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_demographic_cols = [\n",
    "    \"Sex\",\n",
    "    \"Work Status (Category)\",\n",
    "    \"Symptom Duration\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73311c11-b1cb-4810-8717-1df7d9e7c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in categorical_demographic_cols:\n",
    "    plot_categorical_demographics(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3871d17a-daa4-4cec-bd9a-f89f0cc8a997",
   "metadata": {},
   "source": [
    "# Best across Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfdffd3-3046-46dc-bec6-197ed66bd4a3",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957bb027-815a-4a52-917f-73a0e33aa27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_across_trials_idx = [*analysis_idx, 'Mean', 'STD']\n",
    "best_across_trials_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15301ad6-9a43-4ab8-8a46-761212991ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the values of one column when the value of another is among the n-highest (default to n=1)\n",
    "def get_peak_at_max_other(target_col, other_col, df=performance_metric_df, n=1) -> pd.DataFrame:\n",
    "    # Get the best value per analytical grouping and replicate across all trials\n",
    "    peak_value_df = df.sort_values(by=other_col).groupby([*analysis_idx, 'replicate']).tail(n)\n",
    "\n",
    "    # Set up the return dataframe\n",
    "    analysis_groups = peak_value_df.reset_index().groupby(analysis_idx)\n",
    "    value_means = analysis_groups[target_col].mean()\n",
    "    value_stds = analysis_groups[target_col].std()\n",
    "    return_df = pd.DataFrame(index=list(value_means.index))\n",
    "    return_df['Mean'] = value_means\n",
    "    return_df['STD'] = value_stds\n",
    "\n",
    "    # Return the result\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d2a1c-0b11-4b33-b9c6-67dfc5264195",
   "metadata": {},
   "source": [
    "## Balanced Accuracy (Test at Peak Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea0023-0e48-4dda-92c8-2cbc1b06db6e",
   "metadata": {},
   "source": [
    "### Test @ Peak Validation **[MAIN RESULT]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfec9b2-e7d4-44f8-9096-5ed7d15236b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_peak_at_max_other('balanced_accuracy (test)', 'balanced_accuracy (validate)').sort_values(by='Mean').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9494b-c626-41bf-8a18-29caa9a717a2",
   "metadata": {},
   "source": [
    "### Test @ Peak Test [Theoretical Potential]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da88fa4e-7163-433d-b01b-71e779b38e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_peak_at_max_other('balanced_accuracy (test)', 'balanced_accuracy (test)').sort_values(by='Mean').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed3d404-e520-4ee5-9734-2ee0e00ad774",
   "metadata": {},
   "source": [
    "# Performance Across Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9383a84-3b77-4352-9e45-6b47fbd3151b",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff682b-347b-4004-8adb-8470e7b8b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_performance_across_trials(df, metric, grouping, fpath):\n",
    "    # Plot the average and standard deviation\n",
    "    sns.lineplot(data=df, x='trial', y=metric, hue=grouping)\n",
    "\n",
    "    # Add details\n",
    "    plt.title(f'By {grouping.capitalize()} (Average)')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and show the plot\n",
    "    plt.savefig(fpath)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b116a5-ab3e-4387-b1f3-626b8e91b0c7",
   "metadata": {},
   "source": [
    "## Balanced Accuracy (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248169f-4ee4-4115-b23c-e27441b58943",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"figures/bacc_performance/\")\n",
    "if not output_dir.exists():\n",
    "    output_dir.mkdir(parents=True)\n",
    "\n",
    "for i in analysis_idx:\n",
    "    plot_average_performance_across_trials(performance_metric_df, 'balanced_accuracy (test)', i, output_dir/f'bacc_avg_by_{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8474a6ad-9f6e-40ef-88be-ea416c9ca155",
   "metadata": {},
   "source": [
    "## Balanced Accuracy (Test) at Peak Balanced Accuracy (Validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43725ba8-1975-4b89-b429-c1e77ce6aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_at_peak_other_across_trials(df, metric, other, grouping, fpath):\n",
    "    # Reformat the data to be max by trial/replicate grouping\n",
    "    tmp_df = df.sort_values(other).groupby(['replicate', 'trial', grouping]).tail(1).reset_index()\n",
    "    \n",
    "    # Plot the average and standard deviation\n",
    "    sns.lineplot(data=tmp_df, x='trial', y=metric, hue=grouping)\n",
    "\n",
    "    # Add details\n",
    "    plt.title(f'By {grouping.capitalize()} (B.Acc Test @ Peak Validation)')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and show the plot\n",
    "    plt.savefig(fpath)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d9d92-9343-446f-bcbe-f39f1359a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in analysis_idx:\n",
    "    plot_metric_at_peak_other_across_trials(performance_metric_df, 'balanced_accuracy (test)', 'balanced_accuracy (validate)', i, output_dir/f'bacc_test_at_peak_validate_by_{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa491634-113a-4ce2-912a-758981068e16",
   "metadata": {},
   "source": [
    "## Balanced Accuracy (Test) Weighted by Balanced Accuracy (Validated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee2434b-76d4-46ff-a567-ea996f6ce7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_std(vals, weights):\n",
    "    mean_val = np.average(vals, weights=weights)\n",
    "    std_vals = np.average((vals-mean_val)**2, weights=weights)\n",
    "    return std_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714f118e-6bc9-4b31-9809-54e1abf1735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_weighted_by_other(df, metric, weight, grouping, fpath):\n",
    "    # Calculate the weighted metrics from the original dataset\n",
    "    df_groupedby = df.loc[:, [grouping, *study_idxs, metric, weight]].groupby([grouping, 'trial'])\n",
    "    mean_vals = df_groupedby.apply(lambda x: np.average(x[metric], weights=x[weight]), include_groups=False)\n",
    "    std_vals = df_groupedby.apply(lambda x: weighted_std(x[metric], x[weight]), include_groups=False)\n",
    "    \n",
    "    sub_df = pd.DataFrame()\n",
    "    sub_df['Mean'] = mean_vals\n",
    "    sub_df['STD'] = std_vals\n",
    "\n",
    "    # Plot each of them iteratively, w/ weighted mean and std\n",
    "    fig, ax = plt.subplots(1)\n",
    "    group_options = set(df[grouping])\n",
    "    for i, g in enumerate(group_options):\n",
    "        # Plot the main line\n",
    "        y = sub_df.reset_index().query(f\"{grouping} == '{g}'\")\n",
    "        y_mean = y.groupby('trial')['Mean'].mean()\n",
    "        ax.plot(y_mean, label=g)\n",
    "\n",
    "        # Plot the (weighted) standard deviation fills\n",
    "        y_std = y.groupby('trial')['STD'].mean()\n",
    "        ax.fill_between(np.arange(y_std.shape[0]), y_mean+y_std, y_mean-y_std, facecolor=f'C{i}', alpha=0.2)\n",
    "\n",
    "    # Add other plotted elements\n",
    "    plt.xlabel('Trial')\n",
    "    plt.ylabel('Weighted Average')\n",
    "    plt.legend(title=grouping)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e0313-55f1-4810-9ad9-bdbce9a6cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in analysis_idx:\n",
    "    metric_weighted_by_other(performance_metric_df, 'balanced_accuracy (test)', 'balanced_accuracy (validate)', i, output_dir/f'bacc_weighted_avg_by_{i}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e99e8b-13ee-4ca6-8486-ac69f7d9ba8c",
   "metadata": {},
   "source": [
    "# Statistical Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb963b73-3a75-4c9c-a6ca-246f42f857cf",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb0928-c546-4b1f-bc10-47c76357ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "from scipy.stats import ranksums, kruskal, false_discovery_control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74469ad1-a268-4bb7-9781-9662e5752be9",
   "metadata": {},
   "source": [
    "Target metric gathering function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e29e5-bfaa-406d-9228-4f01903673e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute peak values by replicate, mean and std\n",
    "def get_best_per_replicate(target_value):\n",
    "    component_dfs = []\n",
    "    for k, df in df_map.items():\n",
    "        peak_df = df.sort_values(by=target_value).groupby('replicate').last()\n",
    "        peak_df = peak_df.loc[:, [*analysis_idx, 'trial', target_value]]\n",
    "        component_dfs.append(peak_df)\n",
    "    result_df = pd.concat(component_dfs).reset_index()\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29494e-3290-4d5b-b382-cd2e1f2f495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values of one metric, sampled at the peak value of another, per-replicate mean and STD sampled\n",
    "def get_val_at_best_other_per_replicate(target, other, ascending=True, tie_threshold=-1):\n",
    "    component_dfs = []\n",
    "    for k, df in df_map.items():\n",
    "        # Get the best value in the set, as sorted by other\n",
    "        peak_other = df.sort_values(by=other, ascending=ascending).groupby('replicate').last()[other]\n",
    "\n",
    "        # For each entry in the peak values, query the sub_df which matches \n",
    "        comp_dfs = []\n",
    "        for rep_idx in peak_other.index:\n",
    "            peak_val = peak_other[rep_idx]\n",
    "            sub_df = df.query(f\"replicate == {rep_idx} and `{other}` == {peak_val}\")\n",
    "            # If the user specified a tie threshold, only track the chart if the number of ties is less than that number\n",
    "            if tie_threshold > 0 and sub_df.shape[0] > tie_threshold:\n",
    "                print(f\"Skipped {k} [{rep_idx}], as No. Tied Values was greater than threshold: {sub_df.shape[0]}\")\n",
    "                continue\n",
    "            comp_dfs.append(sub_df)\n",
    "            \n",
    "        # If all of the dataframes failed to be tracked due to the tie threshold, skip this loop\n",
    "        if len(comp_dfs) < 1:\n",
    "            print(f\"Entry for {k} skipped, as no replicates were under the tie threshold.\")\n",
    "            continue\n",
    "        peak_df = pd.concat(comp_dfs).loc[:, [*analysis_idx, 'replicate', target, other]]\n",
    "\n",
    "        # Append the result to our list\n",
    "        component_dfs.append(peak_df)\n",
    "    result_df = pd.concat(component_dfs).reset_index()\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c576c18-a23f-4aac-a534-1fccac6d7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_keys = {\n",
    "    'two-sided': '!=',\n",
    "    'greater':   '>',\n",
    "    'less':      '<'\n",
    "}\n",
    "\n",
    "def paired_rankedsum(df, query, target, alternative='two-sided'):\n",
    "    pvals = {}\n",
    "    query_set = set(df[query])\n",
    "\n",
    "    # Caclulate the native rankedsum p-value for each pair of datasets, testing whether the former's value is greater than the latters\n",
    "    for v1, v2 in permutations(query_set, 2):\n",
    "        x1 = df.query(f\"{query} == '{v1}'\")[target]\n",
    "        x2 = df.query(f\"{query} == '{v2}'\")[target]\n",
    "        p = ranksums(x1, x2, alternative=alternative).pvalue\n",
    "        pvals[f\"{v1} {alt_keys[alternative]} {v2}\"] = [p]\n",
    "\n",
    "    # Save the results as a dataframe\n",
    "    return_df = pd.DataFrame.from_dict(pvals).T\n",
    "    return_df.index.name = 'Comparison'\n",
    "    return_df.columns = ['p']\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4112b1d-99d1-4a9d-b939-0d4bfab9a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kw(df, grouping, target):\n",
    "    query_set = set(df[grouping])\n",
    "    samples = [df.query(f\"{grouping} == '{q}'\")[target] for q in query_set]\n",
    "    return kruskal(*samples).pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0a754f-899f-45c9-a9ea-d1a1e21b2fc0",
   "metadata": {},
   "source": [
    "## Testing Balanced Accuracy (All Ties Allowed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b5fb66-24ab-44d4-8ed3-a1faa838c327",
   "metadata": {},
   "source": [
    "### Testing @ Peak Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f258de9-0c58-423b-813d-cb4a4f4d5c1b",
   "metadata": {},
   "source": [
    "#### Raw Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3dda71-9fa8-47fe-a7e9-9cbac4ed718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'balanced_accuracy (test)'\n",
    "other = 'balanced_accuracy (validate)'\n",
    "replicate_test_at_peak_bacc_df = get_val_at_best_other_per_replicate(target, other)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d25719-926c-4fe5-8818-2fd245ba3107",
   "metadata": {},
   "source": [
    "#### Ranked-Sum Grouping Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8366d7ae-5bf1-4a4c-aa44-af4a2644f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-values for whether one experimental permutation has greater average balanced accuracy performance than another\n",
    "sub_dfs = []\n",
    "for k in analysis_idx:\n",
    "    tmp_df = paired_rankedsum(replicate_test_at_peak_bacc_df, k, target, alternative='greater')\n",
    "    sub_dfs.append(tmp_df)\n",
    "\n",
    "sig_test_at_peak_valid_df = pd.concat(sub_dfs).sort_values('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4417a3f6-4e66-47c7-bb78-7a27c1372dee",
   "metadata": {},
   "source": [
    "Bonferonni False Detection Correction **[Extremely Conservative]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7f4659-100b-4e3a-a199-d7d70e7dff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well\n",
    "sig_test_at_peak_valid_df['significance (bonferonni)'] = ''\n",
    "bf_ps = sig_test_at_peak_valid_df['p'] * sig_test_at_peak_valid_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    sig_test_at_peak_valid_df.loc[bf_ps < t, 'significance (bonferonni)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d97889f-5507-4a43-a3e1-ea57791321ff",
   "metadata": {},
   "source": [
    "Benjaminini-Yekutieli False-Detection Correction **[Less Conservative, chosen over Benjamini-Hochberg due to our tests not being completely independent]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fff7d4-1ab4-4251-b7e3-df89151a944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well\n",
    "sig_test_at_peak_valid_df['significance (benjaminini-yekutieli)'] = ''\n",
    "by_ps = false_discovery_control(sig_test_at_peak_valid_df['p'], method='by')\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    sig_test_at_peak_valid_df.loc[by_ps < t, 'significance (benjaminini-yekutieli)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d91a5-f530-4524-905f-42ae962c621e",
   "metadata": {},
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274743cf-0cb2-49d8-9083-d2f05bb1cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_test_at_peak_valid_df.reset_index().head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1e38bf-d76e-4598-a08c-04ad91479360",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379303ef-6892-47ba-b845-af452ddf7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Kruskal-Wallace, confirm that there is a significant difference in the best-case performance for each analytical variation\n",
    "kw_pvals = {}\n",
    "for i in analysis_idx:\n",
    "    kw_pvals[i] = [evaluate_kw(replicate_test_at_peak_bacc_df, i, 'balanced_accuracy (test)')]\n",
    "kw_df = pd.DataFrame.from_dict(kw_pvals).T\n",
    "kw_df.columns = ['p']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ab5b6a-b69b-415d-b4cc-a5d135ca06c5",
   "metadata": {},
   "source": [
    "Bonferonni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd79bcd-0ea5-491a-893d-6f78b341f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well w/ Bonferroni correction\n",
    "kw_df['significance (bonferonni)'] = ''\n",
    "kw_bf_ps = kw_df['p'] * kw_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    kw_df.loc[kw_bf_ps<t, 'significance (bonferonni)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ab938-c30f-4d12-886d-0df792915670",
   "metadata": {},
   "source": [
    "Benjaminini-Yekutieli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3453ff7-1c26-426f-a193-9801230462cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well w/ Bonferroni correction\n",
    "kw_df['significance (benjaminini-yekutieli)'] = ''\n",
    "kw_bf_ps = kw_df['p'] * kw_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    kw_df.loc[kw_bf_ps<t, 'significance (benjaminini-yekutieli)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cee48a-e649-4e12-a94a-07852bc48090",
   "metadata": {},
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5fd9d7-585c-4ee3-b6f4-77a2a820313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd6a892-581b-4adc-b177-ebe6270483aa",
   "metadata": {},
   "source": [
    "### Testing @ Peak Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1575d0b7-3ff1-44ae-95a9-b086bfdc3429",
   "metadata": {},
   "source": [
    "#### Raw Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d8a7bc-c3d6-4b37-98fb-355113126f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'balanced_accuracy (test)'\n",
    "other = 'objective'\n",
    "replicate_test_at_peak_obj_df = get_val_at_best_other_per_replicate(target, other, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8bbd80-cf2c-466f-98aa-81fce6adac02",
   "metadata": {},
   "source": [
    "#### Ranked-Sum Grouping Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc9748-ad49-406d-a391-2aec8b807eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-values for whether one experimental permutation has greater average balanced accuracy performance than another\n",
    "sub_dfs = []\n",
    "for k in analysis_idx:\n",
    "    tmp_df = paired_rankedsum(replicate_test_at_peak_obj_df, k, target, alternative='greater')\n",
    "    sub_dfs.append(tmp_df)\n",
    "\n",
    "sig_test_at_peak_obj_df = pd.concat(sub_dfs).sort_values('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebead67-b547-4a32-a165-59bca9c24f5d",
   "metadata": {},
   "source": [
    "Bonferonni False Detection Correction **[Extremely Conservative]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523dbb77-83d7-4c1e-ba3a-f43aae51dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well\n",
    "sig_test_at_peak_obj_df['significance (bonferonni)'] = ''\n",
    "bf_ps = sig_test_at_peak_obj_df['p'] * sig_test_at_peak_obj_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    sig_test_at_peak_obj_df.loc[bf_ps < t, 'significance (bonferonni)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a334b6-dc43-4edd-8679-2faea62a1f83",
   "metadata": {},
   "source": [
    "Benjaminini-Yekutieli False-Detection Correction **[Less Conservative, chosen over Benjamini-Hochberg due to our tests not being completely independent]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65fef7d-af2c-4289-b62a-b789eb38669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well\n",
    "sig_test_at_peak_obj_df['significance (benjaminini-yekutieli)'] = ''\n",
    "by_ps = false_discovery_control(sig_test_at_peak_obj_df['p'], method='by')\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    sig_test_at_peak_obj_df.loc[by_ps < t, 'significance (benjaminini-yekutieli)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6d2238-97ea-409f-b74b-f5877577cfb1",
   "metadata": {},
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dfceae-e930-4f41-a2b6-9ec81145a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_test_at_peak_obj_df.reset_index().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d775c15-a66a-4894-a06d-aa6670cae15f",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d18af0-d1bd-4cd3-8c61-450e7f4daed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Kruskal-Wallace, confirm that there is a significant difference in the best-case performance for each analytical variation\n",
    "kw_pvals = {}\n",
    "for i in analysis_idx:\n",
    "    kw_pvals[i] = [evaluate_kw(replicate_test_at_peak_obj_df, i, 'balanced_accuracy (test)')]\n",
    "kw_df = pd.DataFrame.from_dict(kw_pvals).T\n",
    "kw_df.columns = ['p']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b941440-037b-43e4-921c-b1c20a47cb6e",
   "metadata": {},
   "source": [
    "Bonferonni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f7bd5f-cfaf-4cc1-891e-e44c109c2132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well w/ Bonferroni correction\n",
    "kw_df['significance (bonferonni)'] = ''\n",
    "kw_bf_ps = kw_df['p'] * kw_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    kw_df.loc[kw_bf_ps<t, 'significance (bonferonni)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83f3b58-c370-433b-9730-c8002f6fb318",
   "metadata": {},
   "source": [
    "Benjaminini-Yekutieli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4566672-d42f-4316-9a04-87c3787a8ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well w/ Bonferroni correction\n",
    "kw_df['significance (benjaminini-yekutieli)'] = ''\n",
    "kw_bf_ps = kw_df['p'] * kw_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    kw_df.loc[kw_bf_ps<t, 'significance (benjaminini-yekutieli)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aee5af3-a86f-4ec5-ad8d-2796e448f1c0",
   "metadata": {},
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e1f767-681e-44f8-89a4-27cc087163f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db90173-8dfd-4aba-9ad8-d05d6ee57116",
   "metadata": {},
   "source": [
    "## Testing Balanced Accuracy (Tie Threshold of 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac3ee95-eee8-44ad-8a0e-1ef384b878b1",
   "metadata": {},
   "source": [
    "### Testing @ Peak Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff046b5-4cbe-445e-a76e-ada2e3532446",
   "metadata": {},
   "source": [
    "#### Raw Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7628d8f4-706d-43df-b3a5-25fbce086641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = 'balanced_accuracy (test)'\n",
    "other = 'balanced_accuracy (validate)'\n",
    "replicate_test_at_peak_bacc_df = get_val_at_best_other_per_replicate(target, other, tie_threshold=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cc2bbc-4e1e-44e7-aa2b-d42a11672081",
   "metadata": {},
   "source": [
    "#### Ranked-Sum Grouping Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9d4aaa-3b75-4506-87e9-58dc844131c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-values for whether one experimental permutation has greater average balanced accuracy performance than another\n",
    "sub_dfs = []\n",
    "for k in analysis_idx:\n",
    "    tmp_df = paired_rankedsum(replicate_test_at_peak_bacc_df, k, target, alternative='greater')\n",
    "    sub_dfs.append(tmp_df)\n",
    "\n",
    "sig_test_at_peak_valid_df = pd.concat(sub_dfs).sort_values('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75830a8-0778-421e-956f-b8a5b0b47cf0",
   "metadata": {},
   "source": [
    "Bonferonni False Detection Correction **[Extremely Conservative]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e22d62-c006-4f35-b99a-a32c1896a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well\n",
    "sig_test_at_peak_valid_df['significance (bonferonni)'] = ''\n",
    "bf_ps = sig_test_at_peak_valid_df['p'] * sig_test_at_peak_valid_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    sig_test_at_peak_valid_df.loc[bf_ps < t, 'significance (bonferonni)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0c0442-7fde-4658-b553-0896c38ad320",
   "metadata": {},
   "source": [
    "Benjaminini-Yekutieli False-Detection Correction **[Less Conservative, chosen over Benjamini-Hochberg due to our tests not being completely independent]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeae468-762d-4678-937c-50783964236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well\n",
    "sig_test_at_peak_valid_df['significance (benjaminini-yekutieli)'] = ''\n",
    "by_ps = false_discovery_control(sig_test_at_peak_valid_df['p'], method='by')\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    sig_test_at_peak_valid_df.loc[by_ps < t, 'significance (benjaminini-yekutieli)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454c6f7b-6c9d-4d5f-b1a0-4a3a96489d31",
   "metadata": {},
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916efa5-5db2-4c54-8e82-0f7884bae6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_test_at_peak_valid_df.reset_index().head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c05bcc-2c96-4da7-9660-2cfcdabdd8b0",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21ac934-788f-4cc4-b21c-16f240e4d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Kruskal-Wallace, confirm that there is a significant difference in the best-case performance for each analytical variation\n",
    "kw_pvals = {}\n",
    "for i in analysis_idx:\n",
    "    kw_pvals[i] = [evaluate_kw(replicate_test_at_peak_bacc_df, i, 'balanced_accuracy (test)')]\n",
    "kw_df = pd.DataFrame.from_dict(kw_pvals).T\n",
    "kw_df.columns = ['p']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9416881d-f6ce-44ed-a2a2-c137a8dd475c",
   "metadata": {},
   "source": [
    "Bonferonni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64c6527-cc8c-4515-9ea4-7d1d32d3087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well w/ Bonferroni correction\n",
    "kw_df['significance (bonferonni)'] = ''\n",
    "kw_bf_ps = kw_df['p'] * kw_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    kw_df.loc[kw_bf_ps<t, 'significance (bonferonni)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b81f76a-9c47-4315-af8b-7974899dbb1e",
   "metadata": {},
   "source": [
    "Benjaminini-Yekutieli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108285d3-b398-4724-96c8-cfce538ccf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well w/ Bonferroni correction\n",
    "kw_df['significance (benjaminini-yekutieli)'] = ''\n",
    "kw_bf_ps = kw_df['p'] * kw_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    kw_df.loc[kw_bf_ps<t, 'significance (benjaminini-yekutieli)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ebfb9-a9e7-4ea9-8985-c873059337c8",
   "metadata": {},
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c6b1b-9ea2-47a9-8dbe-6934135e151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5de070-256e-4102-a775-d009b049dee1",
   "metadata": {},
   "source": [
    "### Testing @ Peak Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c075486-1982-418d-a632-6965b685cb59",
   "metadata": {},
   "source": [
    "#### Raw Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2363df26-2a2f-4ac9-8a81-f276c559c451",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = 'balanced_accuracy (test)'\n",
    "other = 'objective'\n",
    "replicate_test_at_peak_obj_df = get_val_at_best_other_per_replicate(target, other, ascending=False, tie_threshold=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2155cf1e-5416-41ad-8533-2a3438c14d49",
   "metadata": {},
   "source": [
    "#### Ranked-Sum Grouping Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf0482-f754-46da-aa18-f68abbbd2ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-values for whether one experimental permutation has greater average balanced accuracy performance than another\n",
    "sub_dfs = []\n",
    "for k in analysis_idx:\n",
    "    tmp_df = paired_rankedsum(replicate_test_at_peak_obj_df, k, target, alternative='greater')\n",
    "    sub_dfs.append(tmp_df)\n",
    "\n",
    "sig_test_at_peak_obj_df = pd.concat(sub_dfs).sort_values('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d6ea24-f98e-4c39-a502-aed8c6d13fc8",
   "metadata": {},
   "source": [
    "Bonferonni False Detection Correction **[Extremely Conservative]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85008128-2546-45a5-be39-17d2d7dcf1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well\n",
    "sig_test_at_peak_obj_df['significance (bonferonni)'] = ''\n",
    "bf_ps = sig_test_at_peak_obj_df['p'] * sig_test_at_peak_obj_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    sig_test_at_peak_obj_df.loc[bf_ps < t, 'significance (bonferonni)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a212bb05-2bf6-4850-ba72-4a5ccbf7b9f0",
   "metadata": {},
   "source": [
    "Benjaminini-Yekutieli False-Detection Correction **[Less Conservative, chosen over Benjamini-Hochberg due to our tests not being completely independent]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a51430f-3e5c-44b2-935b-eb923d0d9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well\n",
    "sig_test_at_peak_obj_df['significance (benjaminini-yekutieli)'] = ''\n",
    "by_ps = false_discovery_control(sig_test_at_peak_obj_df['p'], method='by')\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    sig_test_at_peak_obj_df.loc[by_ps < t, 'significance (benjaminini-yekutieli)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee070f97-37eb-4afe-a8cd-9a21a94963e1",
   "metadata": {},
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c3f6d-efc1-47e3-9310-cc87719f3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_test_at_peak_valid_df.reset_index().head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e598037-a10b-4e50-b3c1-338bbe81ab62",
   "metadata": {},
   "source": [
    "#### Kruskal-Wallace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a58157-9018-427c-b03b-d0197a6f7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Kruskal-Wallace, confirm that there is a significant difference in the best-case performance for each analytical variation\n",
    "kw_pvals = {}\n",
    "for i in analysis_idx:\n",
    "    kw_pvals[i] = [evaluate_kw(replicate_test_at_peak_obj_df, i, 'balanced_accuracy (test)')]\n",
    "kw_df = pd.DataFrame.from_dict(kw_pvals).T\n",
    "kw_df.columns = ['p']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8192d49d-f3fb-4f3f-b256-0a03a562ae73",
   "metadata": {},
   "source": [
    "Bonferonni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf52187-ebc8-4886-8d86-ddb73ab37e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well w/ Bonferroni correction\n",
    "kw_df['significance (bonferonni)'] = ''\n",
    "kw_bf_ps = kw_df['p'] * kw_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    kw_df.loc[kw_bf_ps<t, 'significance (bonferonni)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943e6499-6418-4345-8887-8bd4415d1651",
   "metadata": {},
   "source": [
    "Benjaminini-Yekutieli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57925b-5b3e-4b8d-bde3-1e725ad9904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the corrected p-value significance as well w/ Bonferroni correction\n",
    "kw_df['significance (benjaminini-yekutieli)'] = ''\n",
    "kw_bf_ps = kw_df['p'] * kw_df.shape[0]\n",
    "for i, t in enumerate([0.05, 0.01, 0.001]):\n",
    "    kw_df.loc[kw_bf_ps<t, 'significance (benjaminini-yekutieli)'] = '*'*(i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6605a1b-3591-4d74-8f29-799fa728aa9e",
   "metadata": {},
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69add2-ab17-41a1-9100-982f585b9964",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663f8e27-6b04-40cd-8153-3d12f85307c5",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cc2509-ff5c-4ec7-97e7-c9632dd3b45c",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74bd963-7fc0-49ae-b481-c667a37a7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_feature_imp(val):\n",
    "    # Strip leading and trailing brackets\n",
    "    val = val[1:-2]\n",
    "\n",
    "    # Create a dictionary from the remaining components\n",
    "    imp_dict = dict()\n",
    "    for v in val.split(', '):\n",
    "        vcomps = v.split(': ')\n",
    "        k = ': '.join(vcomps[:-1])\n",
    "        v = float(vcomps[-1])\n",
    "        imp_dict[k] = v\n",
    "        \n",
    "    return imp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d6d00a-69b7-44e1-870b-41de43d7ce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_report(df: pd.DataFrame, weight_col, feature_col):\n",
    "    # Convert the dictionaries contained with the feature_col dicts into dataframes which can be stacked\n",
    "    raw_dfs = []\n",
    "    weighted_dfs = []\n",
    "    for r in df.iterrows():\n",
    "        rvals = r[1]\n",
    "        tmp_df = pd.DataFrame.from_dict({k: [v] for k, v in rvals[feature_col].items()})\n",
    "        weight = rvals[weight_col]\n",
    "        raw_dfs.append(tmp_df)\n",
    "        weighted_dfs.append(tmp_df * weight)\n",
    "\n",
    "    # Stack the dataframes\n",
    "    raw_feature_imps = pd.concat(raw_dfs).fillna(0)\n",
    "    weighted_feature_imps = pd.concat(weighted_dfs).fillna(0)\n",
    "\n",
    "    # Interpret the results into a clean report\n",
    "    feature_imp_report = {\n",
    "        \"Mean (Raw)\": raw_feature_imps.mean(),\n",
    "        \"STD (Raw)\": raw_feature_imps.std(),\n",
    "        \"Mean (Performance Weighted)\": weighted_feature_imps.mean(),\n",
    "        \"STD (Performance Weighted)\": weighted_feature_imps.std(),\n",
    "    }\n",
    "    result_df = pd.DataFrame.from_dict(feature_imp_report)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f5bee5-930a-448e-99be-dfcee856a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_imp_report(df: pd.DataFrame, feature_col, weight_col) -> pd.DataFrame:\n",
    "    # Convert the dictionaries contained with the feature_col dicts into dataframes which can be stacked\n",
    "    raw_dfs = []\n",
    "    weighted_dfs = []\n",
    "    for r in df.iterrows():\n",
    "        rvals = r[1]\n",
    "        tmp_df = pd.DataFrame.from_dict({k: [v] for k, v in rvals[feature_col].items()})\n",
    "        raw_dfs.append(tmp_df)\n",
    "\n",
    "    # Stack the dataframes\n",
    "    raw_feature_imps = pd.concat(raw_dfs).fillna(0)\n",
    "\n",
    "    # Query the weights list a single time to avoid repeated querying expense\n",
    "    weights = df[weight_col]\n",
    "    \n",
    "    # For each feature, calculate our desired statistics\n",
    "    return_cols = ['Mean', 'STD', 'Weighted Mean', 'Weighted STD']\n",
    "    return_df_dict = {}\n",
    "    for c in raw_feature_imps.columns:\n",
    "        # Single query of the dataframe, as pandas can be slow w/ repeated queries\n",
    "        samples = raw_feature_imps[c]\n",
    "        # Raw Mean\n",
    "        c_mean = np.mean(samples)\n",
    "        # Raw STD\n",
    "        c_std = np.std(samples)\n",
    "        # Weighted mean\n",
    "        c_mean_weighted = np.average(samples, weights=weights)\n",
    "        # Weighted STD\n",
    "        c_std_weighted = weighted_std(samples, weights)\n",
    "        # Stack them into a list and store it in the dictionary\n",
    "        return_df_dict[c] = [c_mean, c_std, c_mean_weighted, c_std_weighted]\n",
    "\n",
    "    # Return the result as a dataframe\n",
    "    return pd.DataFrame.from_dict(return_df_dict, columns=return_cols, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c6a5a1-b404-458d-8c48-96f958cea7c3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1798fd-75d9-4364-8c9a-c549a655b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate and stack the information relative to the value\n",
    "sub_dfs = []\n",
    "\n",
    "for df in df_map.values():\n",
    "    tmp_df = df.loc[:, [*study_idxs, *analysis_idx, 'balanced_accuracy (test)', 'importance_by_permutation (test)']]\n",
    "    sub_dfs.append(tmp_df)\n",
    "\n",
    "feature_imp_df = pd.concat(sub_dfs)\n",
    "\n",
    "# Isolate only the best trial from each replicate\n",
    "feature_imp_df = feature_imp_df.sort_values('balanced_accuracy (test)').groupby([*analysis_idx, 'replicate']).tail(1).set_index(analysis_idx)\n",
    "\n",
    "# Parse the feature importance list into a cleaner dictionary\n",
    "feature_imp_df['importance_by_permutation (test)'] = feature_imp_df['importance_by_permutation (test)'].apply(format_feature_imp)\n",
    "feature_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd1eaf4-20b7-4dc0-971f-eb8878f757a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate PCA-derived features from the rest\n",
    "pca_feature_imp_df = feature_imp_df.reset_index().loc[feature_imp_df.reset_index()['prep'].apply(lambda x: 'pca' in x), :].set_index([*analysis_idx])\n",
    "pca_feature_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb2472b-9c5a-4984-ba62-c7b04eab4962",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpca_feature_imp_df = feature_imp_df.drop(pca_feature_imp_df.index)\n",
    "nonpca_feature_imp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a8fbf-9283-45a1-9e22-fb7b33875ea6",
   "metadata": {},
   "source": [
    "## Un-transformed Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a89023-df3e-480b-9358-d39635bafcf0",
   "metadata": {},
   "source": [
    "### Full dataset (C2C6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a715b7-8623-485f-9f75-b7cdf22cc452",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_feature_imp_df = nonpca_feature_imp_df.query(\"dataset == 'full_C2C6'\")\n",
    "full_feature_report = feature_imp_report(full_feature_imp_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "full_feature_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e51f0-642e-4da3-8def-88dd33110466",
   "metadata": {},
   "source": [
    "### Image-derived features only (C2C6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4954bda7-4083-4d28-97c3-9381d279ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_feature_imp_df = nonpca_feature_imp_df.query(\"dataset == 'img_only_C2C6'\")\n",
    "img_feature_report = feature_imp_report(img_feature_imp_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "img_feature_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666ff53-f073-4028-bdc7-017dc6afe3a7",
   "metadata": {},
   "source": [
    "### Full dataset (C2C7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329f464-8d11-424a-9934-d4a68cb4770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_feature_imp_df = nonpca_feature_imp_df.query(\"dataset == 'full_C2C7'\")\n",
    "full_feature_report = feature_imp_report(full_feature_imp_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "full_feature_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81d091d-74e6-4f3a-aece-df6169d7426b",
   "metadata": {},
   "source": [
    "### Image-derived features only (C2C7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82faba7f-218e-45e2-991d-6f3a69ea5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_feature_imp_df = nonpca_feature_imp_df.query(\"dataset == 'img_only_C2C7'\")\n",
    "img_feature_report = feature_imp_report(img_feature_imp_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "img_feature_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae32df16-f4b2-4db1-958f-c10a4184fb95",
   "metadata": {},
   "source": [
    "### Clinical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c18647-7cb0-40c0-82a8-a277a72110a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clin_feature_imp_df = nonpca_feature_imp_df.query(\"dataset == 'clin_only'\")\n",
    "clin_feature_report = feature_imp_report(clin_feature_imp_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "clin_feature_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0750b9-8536-4b82-83ee-b5c1807e97cb",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49dab40-066a-4e3d-9d63-8d23ec690e50",
   "metadata": {},
   "source": [
    "#### Full (C2C6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4c3c2-4897-430b-8157-2e023aee9a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pca_imp_df = pca_feature_imp_df.query(\"dataset == 'full_C2C6'\")\n",
    "full_pca_report = feature_imp_report(full_pca_imp_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "full_pca_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c8e864-aadc-4f89-aba2-370a0283064c",
   "metadata": {},
   "source": [
    "#### Full (C2C7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4ec3b-2e22-4411-bcce-76a61fe5f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pca_imp_df = pca_feature_imp_df.query(\"dataset == 'full_C2C7'\")\n",
    "full_pca_report = feature_imp_report(full_pca_imp_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "full_pca_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc621b96-91d9-4858-a0df-454e6d2ba31e",
   "metadata": {},
   "source": [
    "#### Image-Only (C2C6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f401f20-238d-4bd7-a6f1-ef6da5a7fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pca_imp_df = pca_feature_imp_df.query(\"dataset == 'img_only_C2C6'\")\n",
    "img_pca_report = feature_imp_report(img_pca_imp_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "img_pca_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc666d2c-afba-44ec-a5d6-452d05972fce",
   "metadata": {},
   "source": [
    "#### Image-Only (C2C7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73799a8-d811-4798-ac19-0348f5f8c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pca_imp_df = pca_feature_imp_df.query(\"dataset == 'img_only_C2C7'\")\n",
    "img_pca_report = feature_imp_report(img_pca_imp_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "img_pca_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178bc342-33c1-4330-b3ee-a578f2697362",
   "metadata": {},
   "source": [
    "#### Clinical Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b4141c-3a43-44e9-a36a-c9f837191510",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clin_pca_imp_df = pca_feature_imp_df.query(\"dataset == 'clin_only'\")\n",
    "clin_pca_report = feature_imp_report(clin_pca_imp_df, 'importance_by_permutation (test)', 'balanced_accuracy (test)')\n",
    "clin_pca_report.sort_values(\"Mean\", ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
